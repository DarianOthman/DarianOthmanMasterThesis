{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "from scipy.spatial.distance import cosine"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T21:07:54.052169Z",
     "start_time": "2024-05-26T21:07:49.321268400Z"
    }
   },
   "id": "4551c07c0870f883"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "api_key = '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'\n",
    "\n",
    "def get_embeddings(text):\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    data = {\n",
    "        \"input\": text,\n",
    "        \"model\": \"text-embedding-3-large\"\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/embeddings\", headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        embedding = response.json()['data'][0]['embedding']\n",
    "        return np.array(embedding)\n",
    "    else:\n",
    "        print(f\"Error with text: {text[:30]}... Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def similarity(text_embeddings_real, text_embeddings_synthetic):\n",
    "    average_similarities = []\n",
    "    for i, group1_embeddings in enumerate(text_embeddings_real):\n",
    "        for j, group2_embeddings in enumerate(text_embeddings_synthetic):\n",
    "            # Convert embeddings to numpy arrays\n",
    "            group1_embeddings = np.array(group1_embeddings)\n",
    "            group2_embeddings = np.array(group2_embeddings)\n",
    "            \n",
    "            # Calculate cosine similarities between corresponding embeddings\n",
    "            similarity_matrix = cosine_similarity(group1_embeddings, group2_embeddings)\n",
    "            \n",
    "            # Calculate average similarity\n",
    "            average_similarity = np.mean(similarity_matrix)\n",
    "            \n",
    "            # Store the average similarity\n",
    "            average_similarities.append(average_similarity)\n",
    "            \n",
    "    mean_similarity = np.mean(average_similarities)\n",
    "    return mean_similarity, average_similarities\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    return 1 - cosine(vec1, vec2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T21:07:54.107111300Z",
     "start_time": "2024-05-26T21:07:54.062574100Z"
    }
   },
   "id": "738ceab9a0e8294a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "\n",
    "def remove_urls(text):\n",
    "    # Regular expression to find URLs\n",
    "    url_pattern = re.compile(r'http\\S+|www\\S+|https\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def remove_emojis(text):\n",
    "    # Function to remove emojis\n",
    "    return emoji.replace_emoji(text, replace='')\n",
    "\n",
    "def text_cleaning(text):\n",
    "    # Process each row in the list\n",
    "    cleaned_topics = []\n",
    "    for row in text:\n",
    "        no_urls = remove_urls(row)\n",
    "        no_emojis = remove_emojis(no_urls)\n",
    "        cleaned_topics.append(no_emojis)\n",
    "    return cleaned_topics\n",
    "\n",
    "def embeddings(data, real_path, synthetic_path):\n",
    "    text_real=data[1].tolist()\n",
    "    text_real=text_cleaning(text_real)\n",
    "    text_syntethic=data[0].tolist()\n",
    "    text_syntethic=text_cleaning(text_syntethic)\n",
    "    \n",
    "    real_embeddings = [get_embeddings(text) for text in text_real]\n",
    "    for i, embedding in enumerate(real_embeddings):\n",
    "        if embedding is None:\n",
    "            print(\"Retrying...\")\n",
    "            real_embeddings[i] = get_embeddings(text_real[i])\n",
    "            print(\"Fixed!\")\n",
    "    synthetic_embeddings = [get_embeddings(text) for text in text_syntethic]\n",
    "    for i, embedding in enumerate(synthetic_embeddings):\n",
    "        if embedding is None:\n",
    "            print(\"Retrying...\")\n",
    "            synthetic_embeddings[i] = get_embeddings(text_syntethic[i])\n",
    "            print(\"Fixed\")\n",
    "            \n",
    "    with open(real_path, 'wb') as f:\n",
    "        pickle.dump(real_embeddings, f)\n",
    "    with open(synthetic_path, 'wb') as f:\n",
    "        pickle.dump(synthetic_embeddings, f)\n",
    "    return real_embeddings, synthetic_embeddings\n",
    "\n",
    "def simat(real_embeddings,synthetic_embeddings):\n",
    "    num_matrices = len(real_embeddings) // 3  # Calculate the number of matrices\n",
    "    similarity_matrices = []\n",
    "    for k in range(num_matrices):\n",
    "        start_idx = k * 3\n",
    "        end_idx = start_idx + 3\n",
    "        similarity_matrix = np.zeros((3, 3))\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                similarity = cosine_similarity(real_embeddings[start_idx + i], synthetic_embeddings[start_idx + j])\n",
    "                similarity_matrix[i][j] = similarity\n",
    "        similarity_matrices.append(similarity_matrix)\n",
    "    return similarity_matrices"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T21:07:54.174008700Z",
     "start_time": "2024-05-26T21:07:54.097522900Z"
    }
   },
   "id": "59d59c9659ab1803"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TikTok"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb1de6b70096c12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path_synthetic = 'C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Generation_Dutch/Generic_t=1_P=1_TikTok_Dutch.csv'\n",
    "data = pd.read_csv(file_path_synthetic, sep=';', header=None)\n",
    "real_path=\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Generic_t=1_P=1_TikTok_Dutch_emb_real.pkl\"\n",
    "synthetic_path=\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Generic_t=1_P=1_TikTok_Dutch_emb_synthetic.pkl\"\n",
    "gen=embeddings(data, real_path, synthetic_path)\n",
    "real_embeddings_tt_gen=gen[0]\n",
    "synthetic_embeddings_tt_gen=gen[1]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-26T21:07:54.167108400Z"
    }
   },
   "id": "844ab1679969ca5b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path_synthetic = 'C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Generation_Dutch/Content_Aware_t=1_P=1_TikTok_Dutch.csv'\n",
    "data = pd.read_csv(file_path_synthetic, sep=';', header=None)\n",
    "real_path=\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Content_Aware_t=1_P=1_TikTok_Dutch_emb_real.pkl\"\n",
    "synthetic_path=\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Content_Aware_t=1_P=1_TikTok_Dutch_emb_synthetic.pkl\"\n",
    "gen=embeddings(data, real_path, synthetic_path)\n",
    "real_embeddings_tt_ca=gen[0]\n",
    "synthetic_embeddings_tt_ca=gen[1]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "11cf6f86591ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instagram"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c368b98f2e7abd29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path_synthetic = 'C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Generation_Dutch/Generic_t=1_P=1_Instagram_Dutch.csv'\n",
    "data = pd.read_csv(file_path_synthetic, sep=';', header=None)\n",
    "real_path=\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Generic_t=1_P=1_Instagram_Dutch_emb_real.pkl\"\n",
    "synthetic_path=\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Generic_t=1_P=1_Instagram_Dutch_emb_synthetic.pkl\"\n",
    "gen=embeddings(data, real_path, synthetic_path)\n",
    "real_embeddings_ins_gen=gen[0]\n",
    "synthetic_embeddings_ins_gen=gen[1]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ade8fd20f61d705e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path_synthetic = 'C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Generation_Dutch/Content_Aware_t=1_P=1_Instagram_Dutch.csv'\n",
    "data = pd.read_csv(file_path_synthetic, sep=';', header=None)\n",
    "real_path=\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Content_Aware_t=1_P=1_Instagram_Dutch_emb_real.pkl\"\n",
    "synthetic_path=\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Content_Aware_t=1_P=1_Instagram_Dutch_emb_synthetic.pkl\"\n",
    "gen=embeddings(data, real_path, synthetic_path)\n",
    "real_embeddings_ins_ca=gen[0]\n",
    "synthetic_embeddings_ins_ca=gen[1]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1367719ab0bc07a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## YouTube"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88d71cf742a6f57f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path_synthetic = 'C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Generation_Dutch/Generic_t=1_P=1_YouTube_Dutch.csv'\n",
    "data = pd.read_csv(file_path_synthetic, sep=';', header=None)\n",
    "real_path=\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Generic_t=1_P=1_YouTube_Dutch_emb_real.pkl\"\n",
    "synthetic_path=\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Generic_t=1_P=1_YouTube_Dutch_emb_synthetic.pkl\"\n",
    "gen=embeddings(data, real_path, synthetic_path)\n",
    "real_embeddings_yt_gen=gen[0]\n",
    "synthetic_embeddings_yt_gen=gen[1]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f82938ba2ad11f23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path_synthetic = 'C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Generation_Dutch/Content_Aware_t=1_P=1_YouTube_Dutch.csv'\n",
    "data = pd.read_csv(file_path_synthetic, sep=';', header=None)\n",
    "real_path=\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Content_Aware_t=1_P=1_YouTube_Dutch_emb_real.pkl\"\n",
    "synthetic_path=\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Content_Aware_t=1_P=1_YouTube_Dutch_emb_synthetic.pkl\"\n",
    "gen=embeddings(data, real_path, synthetic_path)\n",
    "real_embeddings_yt_ca=gen[0]\n",
    "synthetic_embeddings_yt_ca=gen[1]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b2cda4a66a8ab433"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "real_embeddings_ins_gen = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Generic_t=1_P=1_Instagram_Dutch_emb_real.pkl\", \"rb\"))\n",
    "synthetic_embeddings_ins_gen = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Generic_t=1_P=1_Instagram_Dutch_emb_synthetic.pkl\", \"rb\"))\n",
    "real_embeddings_ins_ca = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Content_Aware_t=1_P=1_Instagram_Dutch_emb_real.pkl\", \"rb\"))\n",
    "synthetic_embeddings_ins_ca = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Content_Aware_t=1_P=1_Instagram_Dutch_emb_synthetic.pkl\", \"rb\"))\n",
    "real_embeddings_tt_gen = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Generic_t=1_P=1_TikTok_Dutch_emb_real.pkl\", \"rb\"))\n",
    "synthetic_embeddings_tt_gen = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Generic_t=1_P=1_TikTok_Dutch_emb_synthetic.pkl\", \"rb\"))\n",
    "real_embeddings_tt_ca = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Content_Aware_t=1_P=1_TikTok_Dutch_emb_real.pkl\", \"rb\"))\n",
    "synthetic_embeddings_tt_ca = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Content_Aware_t=1_P=1_TikTok_Dutch_emb_synthetic.pkl\", \"rb\"))\n",
    "real_embeddings_yt_gen = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Generic_t=1_P=1_YouTube_Dutch_emb_real.pkl\", \"rb\"))\n",
    "synthetic_embeddings_yt_gen = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Generic_t=1_P=1_YouTube_Dutch_emb_synthetic.pkl\", \"rb\"))\n",
    "real_embeddings_yt_ca = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Content_Aware_t=1_P=1_YouTube_Dutch_emb_real.pkl\", \"rb\"))\n",
    "synthetic_embeddings_yt_ca = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Emb_Dutch/Content_Aware_t=1_P=1_YouTube_Dutch_emb_synthetic.pkl\", \"rb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a4096a6913cf5ef6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sim_ins_gen=simat(real_embeddings_ins_gen,synthetic_embeddings_ins_gen)\n",
    "sim_ins_ca=simat(real_embeddings_ins_ca,synthetic_embeddings_ins_ca)\n",
    "sim_tt_gen=simat(real_embeddings_tt_gen,synthetic_embeddings_tt_gen)\n",
    "sim_tt_ca=simat(real_embeddings_tt_ca,synthetic_embeddings_tt_ca)\n",
    "sim_yt_gen=simat(real_embeddings_yt_gen,synthetic_embeddings_yt_gen)\n",
    "sim_yt_ca=simat(real_embeddings_yt_ca,synthetic_embeddings_yt_ca)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2b29f81afd091da8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(len(sim_ins_gen)):\n",
    "    # Flatten the array and get the indices that would sort it\n",
    "    sorted_indices = np.argsort(sim_ins_gen[i].flatten())\n",
    "    \n",
    "    # Extract the highest three values\n",
    "    highest_three_indices = sorted_indices[-3:]\n",
    "    highest_three_values = sim_ins_gen[i].flatten()[highest_three_indices]\n",
    "    \n",
    "    # Extract the lowest three values\n",
    "    lowest_three_indices = sorted_indices[:3]\n",
    "    lowest_three_values = sim_ins_gen[i].flatten()[lowest_three_indices]\n",
    "    average_of_top_3 = np.mean(highest_three_values)\n",
    "    average_of_bottom_3 = np.mean(lowest_three_values)\n",
    "    \n",
    "    results.append([\n",
    "            i,\n",
    "            highest_three_values.tolist(),\n",
    "            average_of_top_3,\n",
    "            lowest_three_values.tolist(),\n",
    "            average_of_bottom_3\n",
    "        ])\n",
    "results_df = pd.DataFrame(results, columns=[\n",
    "    'Set Index',\n",
    "    'Top 3 Similarity Scores',\n",
    "    'Average of Top 3',\n",
    "    'Bottom 3 Similarity Scores',\n",
    "    'Average of Bottom 3'\n",
    "])\n",
    "results_df"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b9fecddb406756fe"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0.48518060052193135"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-cosine(np.array(synthetic_embeddings).flatten(),np.array(real_embeddings).flatten())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T16:03:40.365685800Z",
     "start_time": "2024-05-24T16:03:40.250881200Z"
    }
   },
   "id": "1448efeb1c010581"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "tsne_results = []\n",
    "labels = []\n",
    "list_embeddings = [real_embeddings_ins_gen,synthetic_embeddings_ins_gen,real_embeddings_ins_ca,synthetic_embeddings_ins_ca,real_embeddings_tt_gen,synthetic_embeddings_tt_gen,real_embeddings_tt_ca,synthetic_embeddings_tt_ca,real_embeddings_yt_gen,synthetic_embeddings_yt_gen, real_embeddings_yt_ca,synthetic_embeddings_yt_ca]\n",
    "label_names = ['Instagram Generic Real', 'Instagram Generic Synthetic', 'Instagram Content Aware Real', 'Instagram Content Aware Synthetic', 'TikTok Generic Real', 'TikTok Generic Synthetic', 'TikTok Content Aware Real', 'TikTok Content Aware Synthetic', 'YouTube Generic Real', 'YouTube Generic Synthetic', 'YouTube Content Aware Real', 'YouTube Content Aware Synthetic']\n",
    "color_map= {'Instagram Generic Real': 'blue', 'Instagram Generic Synthetic': 'red', 'Instagram Content Aware Real': 'green', 'Instagram Content Aware Synthetic': 'yellow', 'TikTok Generic Real': 'purple', 'TikTok Generic Synthetic': 'orange', 'TikTok Content Aware Real': 'brown', 'TikTok Content Aware Synthetic': 'pink', 'YouTube Generic Real': 'black', 'YouTube Generic Synthetic': 'grey', 'YouTube Content Aware Real': 'cyan', 'YouTube Content Aware Synthetic': 'magenta'}\n",
    "for list in range(len(list_embeddings)):\n",
    "    embeddings = list_embeddings[list]\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=50, random_state=42)\n",
    "    kmeans.fit(embeddings)\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    \n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_cluster_results = tsne.fit_transform(cluster_centers)\n",
    "    tsne_results.extend(tsne_cluster_results)\n",
    "    labels.extend([label_names[list]] * len(cluster_centers))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "for label, (x, y) in zip(labels, tsne_results):\n",
    "    plt.scatter(x, y, color=color_map[label], label=f'{label}', alpha=0.7)\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "plt.title('t-SNE visualization of k-means centroids')\n",
    "plt.xlabel('t-SNE axis 1')\n",
    "plt.ylabel('t-SNE axis 2')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "763bb3db5444ee79"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
