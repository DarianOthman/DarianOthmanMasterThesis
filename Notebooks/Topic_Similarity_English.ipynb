{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "from scipy.spatial.distance import cosine"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T14:40:56.619760800Z",
     "start_time": "2024-06-11T14:40:56.586951700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "api_key = ''\n",
    "\n",
    "def get_embeddings(text):\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    data = {\n",
    "        \"input\": text,\n",
    "        \"model\": \"text-embedding-3-large\"\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/embeddings\", headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        embedding = response.json()['data'][0]['embedding']\n",
    "        return np.array(embedding)\n",
    "    else:\n",
    "        print(f\"Error with text: {text[:30]}... Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    return 1 - cosine(vec1, vec2)\n",
    "def simat(real_embeddings,synthetic_embeddings):\n",
    "    similarity_matrices=[]\n",
    "\n",
    "    similarity_matrix = np.zeros((len(real_embeddings), len(synthetic_embeddings)))\n",
    "    for i in range(len(real_embeddings)):\n",
    "        for j in range(len(synthetic_embeddings)):\n",
    "            similarity = cosine_similarity(np.concatenate(real_embeddings[i]), np.concatenate(synthetic_embeddings[j]))\n",
    "            similarity_matrix[i][j] = similarity\n",
    "    similarity_matrices.append(similarity_matrix)\n",
    "    return similarity_matrices"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T14:44:09.091556300Z",
     "start_time": "2024-06-11T14:44:09.045431100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "file_path_synthetic = 'C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_Instagram_English_topics.csv'\n",
    "\n",
    "\n",
    "data_synthetic = pd.read_csv(file_path_synthetic, sep=';')\n",
    "topics_synthetic = data_synthetic[\"Representation\"].tolist()\n",
    "topics_synthetic = [eval(list_str) for list_str in topics_synthetic]\n",
    "\n",
    "\n",
    "text_embeddings_synthetic_ins = [[get_embeddings(word) for word in sentence] for sentence in topics_synthetic]\n",
    "with open('C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_Instagram_English_topics_emb.pkl', 'wb') as f:\n",
    "    pickle.dump(text_embeddings_synthetic_ins, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T08:57:14.170965100Z",
     "start_time": "2024-05-22T08:55:39.042346600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "file_path_real = 'C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_Instagram_English_real_topics.csv'\n",
    "\n",
    "\n",
    "data_real = pd.read_csv(file_path_real, sep=';')\n",
    "topics_real = data_real[\"Representation\"].tolist()\n",
    "topics_real = [eval(list_str) for list_str in topics_real]\n",
    "\n",
    "\n",
    "text_embeddings_real_ins = [[get_embeddings(word) for word in sentence] for sentence in topics_real]\n",
    "with open('C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_Instagram_English_real_topics_emb.pkl', 'wb') as f:\n",
    "    pickle.dump(text_embeddings_real_ins, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T08:59:29.184110700Z",
     "start_time": "2024-05-22T08:57:14.170965100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "file_path_synthetic = 'C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_YouTube_English_topics.csv'\n",
    "\n",
    "\n",
    "data_synthetic = pd.read_csv(file_path_synthetic, sep=';')\n",
    "topics_synthetic = data_synthetic[\"Representation\"].tolist()\n",
    "topics_synthetic = [eval(list_str) for list_str in topics_synthetic]\n",
    "\n",
    "\n",
    "text_embeddings_synthetic_yt = [[get_embeddings(word) for word in sentence] for sentence in topics_synthetic]\n",
    "with open('C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_YouTube_English_topics_emb.pkl', 'wb') as f:\n",
    "    pickle.dump(text_embeddings_synthetic_yt, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T09:00:57.970989Z",
     "start_time": "2024-05-22T08:59:29.184110700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "file_path_real = 'C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_YouTube_English_real_topics.csv'\n",
    "\n",
    "\n",
    "data_real = pd.read_csv(file_path_real, sep=';')\n",
    "topics_real = data_real[\"Representation\"].tolist()\n",
    "topics_real = [eval(list_str) for list_str in topics_real]\n",
    "\n",
    "\n",
    "text_embeddings_real_yt = [[get_embeddings(word) for word in sentence] for sentence in topics_real]\n",
    "with open('C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_YouTube_English_real_topics_emb.pkl', 'wb') as f:\n",
    "    pickle.dump(text_embeddings_real_yt, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T09:03:12.857830800Z",
     "start_time": "2024-05-22T09:00:57.979707600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "file_path_synthetic = 'C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_TikTok_English_topics.csv'\n",
    "\n",
    "\n",
    "data_synthetic = pd.read_csv(file_path_synthetic, sep=';')\n",
    "topics_synthetic = data_synthetic[\"Representation\"].tolist()\n",
    "topics_synthetic = [eval(list_str) for list_str in topics_synthetic]\n",
    "\n",
    "\n",
    "text_embeddings_synthetic_tt = [[get_embeddings(word) for word in sentence] for sentence in topics_synthetic]\n",
    "with open('C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_TikTok_English_topics_emb.pkl', 'wb') as f:\n",
    "    pickle.dump(text_embeddings_synthetic_tt, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T09:04:06.986547400Z",
     "start_time": "2024-05-22T09:03:12.857830800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "file_path_real = 'C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_TikTok_English_real_topics.csv'\n",
    "\n",
    "\n",
    "data_real = pd.read_csv(file_path_real, sep=';')\n",
    "topics_real = data_real[\"Representation\"].tolist()\n",
    "topics_real = [eval(list_str) for list_str in topics_real]\n",
    "\n",
    "\n",
    "text_embeddings_real_tt = [[get_embeddings(word) for word in sentence] for sentence in topics_real]\n",
    "with open('C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_TikTok_English_real_topics_emb.pkl', 'wb') as f:\n",
    "    pickle.dump(text_embeddings_real_tt, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T09:05:31.126227100Z",
     "start_time": "2024-05-22T09:04:06.993172400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "real_embeddings_ins_gen = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_Instagram_English_real_topics_emb.pkl\", \"rb\"))\n",
    "synthetic_embeddings_ins_gen = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_Instagram_English_topics_emb.pkl\", \"rb\"))\n",
    "real_embeddings_tt_gen=pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_TikTok_English_real_topics_emb.pkl\", \"rb\"))\n",
    "synthetic_embeddings_tt_gen=pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_TikTok_English_topics_emb.pkl\", \"rb\"))\n",
    "real_embeddings_yt_gen=pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_YouTube_English_real_topics_emb.pkl\", \"rb\"))\n",
    "synthetic_embeddings_yt_gen=pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Generic_t=1_P=1_YouTube_English_topics_emb.pkl\", \"rb\"))\n",
    "real_embeddings_ins_ca = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Content_Aware_t=1_P=1_Instagram_English_real_topics_emb.pkl\", \"rb\"))\n",
    "synthetic_embeddings_ins_ca = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Content_Aware_t=1_P=1_Instagram_English_topics_emb.pkl\", \"rb\"))\n",
    "real_embeddings_tt_ca = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Content_Aware_t=1_P=1_TikTok_English_real_topics_emb.pkl\", \"rb\"))\n",
    "synthetic_embeddings_tt_ca = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Content_Aware_t=1_P=1_TikTok_English_topics_emb.pkl\", \"rb\"))\n",
    "real_embeddings_yt_ca = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Content_Aware_t=1_P=1_YouTube_English_real_topics_emb.pkl\", \"rb\"))\n",
    "synthetic_embeddings_yt_ca = pickle.load(open(\"C:/Users/I6240624/Documents/BISS/Master Thesis/Code/DarianOthmanMasterThesis/Topic_English/Content_Aware_t=1_P=1_YouTube_English_topics_emb.pkl\", \"rb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:04:10.760177400Z",
     "start_time": "2024-06-11T15:04:10.637501800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "sim_ins_gen=simat(real_embeddings_ins_gen,synthetic_embeddings_ins_gen)\n",
    "sim_ins_ca=simat(real_embeddings_ins_ca,synthetic_embeddings_ins_ca)\n",
    "sim_tt_gen=simat(real_embeddings_tt_gen,synthetic_embeddings_tt_gen)\n",
    "sim_tt_ca=simat(real_embeddings_tt_ca,synthetic_embeddings_tt_ca)\n",
    "sim_yt_gen=simat(real_embeddings_yt_gen,synthetic_embeddings_yt_gen)\n",
    "sim_yt_ca=simat(real_embeddings_yt_ca,synthetic_embeddings_yt_ca)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:04:57.293715800Z",
     "start_time": "2024-06-11T15:04:56.816097200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "   Matrix List  Total Mean\n0  sim_ins_gen    0.170451\n1   sim_ins_ca    0.151688\n2   sim_tt_gen    0.161853\n3    sim_tt_ca    0.164687\n4   sim_yt_gen    0.157570\n5    sim_yt_ca    0.154187",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Matrix List</th>\n      <th>Total Mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sim_ins_gen</td>\n      <td>0.170451</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sim_ins_ca</td>\n      <td>0.151688</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sim_tt_gen</td>\n      <td>0.161853</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sim_tt_ca</td>\n      <td>0.164687</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sim_yt_gen</td>\n      <td>0.157570</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>sim_yt_ca</td>\n      <td>0.154187</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lists = [sim_ins_gen, sim_ins_ca, sim_tt_gen, sim_tt_ca, sim_yt_gen, sim_yt_ca]\n",
    "list_names = ['sim_ins_gen', 'sim_ins_ca', 'sim_tt_gen', 'sim_tt_ca', 'sim_yt_gen', 'sim_yt_ca']\n",
    "\n",
    "# Function to calculate the total mean of all the means for a list of matrices\n",
    "def calculate_total_mean(matrix_list):\n",
    "    means = []\n",
    "    for matrix in matrix_list:\n",
    "        means.append(np.min(matrix))\n",
    "    total_mean = np.mean(means)\n",
    "    return total_mean\n",
    "\n",
    "# Prepare data for the table\n",
    "data = []\n",
    "\n",
    "for i, matrix_list in enumerate(all_lists):\n",
    "    total_mean = calculate_total_mean(matrix_list)\n",
    "    data.append([list_names[i], total_mean])\n",
    "\n",
    "# Create a DataFrame\n",
    "similaritydf = pd.DataFrame(data, columns=['Matrix List', 'Total Mean'])\n",
    "\n",
    "# Display the table\n",
    "similaritydf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:19:13.671133800Z",
     "start_time": "2024-06-11T15:19:13.620419100Z"
    }
   }
  }
 ]
}
